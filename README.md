# Twitter-Sentiment-Analysis

In the Internet age, hate speech online has become an increasingly pressing issue, and it is vital to be able to efficiently automate a hate-recognition algorithm to identify such instances. Past research has seen success making use of Support Vector Machines, and templates ([intensity][user intent][hate target]), or keywords. Although existing research suggests “neural models have significantly higher AUC scores than the non-neural baseline”, we would like to see if less computationally expensive models can perform reasonably well.

This project aims to evaluate and compare the performance of two models: Naive Bayes Classifier and Logistic Regression, in classifying tweets as either neutral or containing hate speech, as well as the usage of two vectorizers in feature extraction: bag-of-words and term frequency-inverse-document-frequency. Our paper shows that both models were able to effectively identify the presence of hate speech in tweets regardless of the chosen vectorizer, though the vectorizers impact the performance of each model differently. Both models resulted in accuracy scores of 95% and higher, with the Naive Bayes model slightly outperforming Logistic Regression.
